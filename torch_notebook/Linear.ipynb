{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('base': conda)",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d76e67641f13a7514cfb2366f7dfdf9547d0a58412f0f4cc9877d7d1ebfaed14"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1, 1, 2, 2])\ntensor(13.9382, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.0063,  0.2782],\n          [-0.4015, -0.3580]]]], requires_grad=True)\ntensor(12.7090, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.0159,  0.2879],\n          [-0.3918, -0.3483]]]], requires_grad=True)\ntensor(11.5777, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.0256,  0.2975],\n          [-0.3822, -0.3387]]]], requires_grad=True)\ntensor(10.5098, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.0352,  0.3072],\n          [-0.3726, -0.3290]]]], requires_grad=True)\ntensor(9.4948, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.0449,  0.3169],\n          [-0.3628, -0.3193]]]], requires_grad=True)\ntensor(8.5295, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.0548,  0.3268],\n          [-0.3530, -0.3095]]]], requires_grad=True)\ntensor(7.6133, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.0647,  0.3367],\n          [-0.3430, -0.2995]]]], requires_grad=True)\ntensor(6.7472, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.0748,  0.3468],\n          [-0.3330, -0.2895]]]], requires_grad=True)\ntensor(5.9326, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.0849,  0.3570],\n          [-0.3228, -0.2793]]]], requires_grad=True)\ntensor(5.1715, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.0952,  0.3673],\n          [-0.3125, -0.2690]]]], requires_grad=True)\ntensor(4.4662, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.1056,  0.3777],\n          [-0.3021, -0.2586]]]], requires_grad=True)\ntensor(3.8188, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.1161,  0.3882],\n          [-0.2916, -0.2481]]]], requires_grad=True)\ntensor(3.2318, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.1268,  0.3988],\n          [-0.2809, -0.2375]]]], requires_grad=True)\ntensor(2.7075, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.1375,  0.4095],\n          [-0.2702, -0.2267]]]], requires_grad=True)\ntensor(2.2483, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.1483,  0.4204],\n          [-0.2594, -0.2159]]]], requires_grad=True)\ntensor(1.8563, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.1593,  0.4313],\n          [-0.2485, -0.2050]]]], requires_grad=True)\ntensor(1.5337, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.1703,  0.4422],\n          [-0.2375, -0.1940]]]], requires_grad=True)\ntensor(1.2823, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.1814,  0.4533],\n          [-0.2265, -0.1829]]]], requires_grad=True)\ntensor(1.1040, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.1925,  0.4644],\n          [-0.2154, -0.1717]]]], requires_grad=True)\ntensor(1.0002, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.2037,  0.4755],\n          [-0.2042, -0.1605]]]], requires_grad=True)\ntensor(0.9721, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.2150,  0.4867],\n          [-0.1931, -0.1492]]]], requires_grad=True)\ntensor(1.0208, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.2263,  0.4978],\n          [-0.1819, -0.1379]]]], requires_grad=True)\ntensor(1.1468, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.2376,  0.5090],\n          [-0.1707, -0.1266]]]], requires_grad=True)\ntensor(1.3503, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.2489,  0.5202],\n          [-0.1596, -0.1152]]]], requires_grad=True)\ntensor(1.6311, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.2603,  0.5313],\n          [-0.1485, -0.1038]]]], requires_grad=True)\ntensor(1.9883, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.2716,  0.5423],\n          [-0.1375, -0.0925]]]], requires_grad=True)\ntensor(2.4207, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.2828,  0.5532],\n          [-0.1265, -0.0812]]]], requires_grad=True)\ntensor(2.9263, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.2941,  0.5640],\n          [-0.1157, -0.0699]]]], requires_grad=True)\ntensor(3.5024, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.3052,  0.5746],\n          [-0.1051, -0.0588]]]], requires_grad=True)\ntensor(4.1455, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.3162,  0.5851],\n          [-0.0947, -0.0477]]]], requires_grad=True)\ntensor(4.8512, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.3271,  0.5953],\n          [-0.0845, -0.0367]]]], requires_grad=True)\ntensor(5.6140, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.3378,  0.6052],\n          [-0.0746, -0.0259]]]], requires_grad=True)\ntensor(6.4276, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.3484,  0.6147],\n          [-0.0650, -0.0152]]]], requires_grad=True)\ntensor(7.2841, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.3587,  0.6239],\n          [-0.0558, -0.0047]]]], requires_grad=True)\ntensor(8.1745, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.3688,  0.6326],\n          [-0.0471,  0.0055]]]], requires_grad=True)\ntensor(9.0884, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.3786,  0.6408],\n          [-0.0390,  0.0154]]]], requires_grad=True)\ntensor(10.0139, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.3880,  0.6483],\n          [-0.0315,  0.0251]]]], requires_grad=True)\ntensor(10.9376, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.3971,  0.6551],\n          [-0.0246,  0.0344]]]], requires_grad=True)\ntensor(11.8446, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.4057,  0.6611],\n          [-0.0186,  0.0432]]]], requires_grad=True)\ntensor(12.7188, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.4138,  0.6663],\n          [-0.0135,  0.0516]]]], requires_grad=True)\ntensor(13.5430, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.4213,  0.6704],\n          [-0.0093,  0.0596]]]], requires_grad=True)\ntensor(14.2994, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.4283,  0.6735],\n          [-0.0062,  0.0669]]]], requires_grad=True)\ntensor(14.9701, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.4345,  0.6755],\n          [-0.0043,  0.0736]]]], requires_grad=True)\ntensor(15.5377, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.4400,  0.6762],\n          [-0.0036,  0.0796]]]], requires_grad=True)\ntensor(15.9863, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.4447,  0.6756],\n          [-0.0041,  0.0849]]]], requires_grad=True)\ntensor(16.3023, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.4484,  0.6738],\n          [-0.0060,  0.0894]]]], requires_grad=True)\ntensor(16.4750, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.4513,  0.6706],\n          [-0.0091,  0.0930]]]], requires_grad=True)\ntensor(16.4974, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.4531,  0.6661],\n          [-0.0136,  0.0957]]]], requires_grad=True)\ntensor(16.3666, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.4539,  0.6604],\n          [-0.0193,  0.0974]]]], requires_grad=True)\ntensor(16.0839, grad_fn=<MseLossBackward>)\nParameter containing:\ntensor([[[[ 0.4537,  0.6536],\n          [-0.0262,  0.0981]]]], requires_grad=True)\n"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import SGD, Adam\n",
    "torch.manual_seed(0)\n",
    "input = torch.tensor([\n",
    "    [0,0,5],\n",
    "    [0,5,5],\n",
    "    [5,5,10]\n",
    "], dtype=torch.float).unsqueeze(0).unsqueeze(0)\n",
    "w = Conv2d(1, 1, kernel_size=2, stride=1)\n",
    "target = torch.tensor([\n",
    "    [1, 0],\n",
    "    [0, 1]\n",
    "], dtype=torch.float).unsqueeze(0).unsqueeze(0)\n",
    "print(target.shape)\n",
    "epoch = 50\n",
    "# optimizer = SGD(w.parameters(), lr=1e-6)\n",
    "optimizer = Adam(w.parameters(), lr=1e-2)\n",
    "for i in range(epoch):\n",
    "    output = w(input)\n",
    "    func=MSELoss()\n",
    "    loss=func(output, target)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(w.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}